{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae3e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python.components import containers\n",
    "from mediapipe.tasks.python import audio\n",
    "from scipy.io import wavfile\n",
    "import urllib\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "from sklearn import preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1a12c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"yamnet_audio_classifier_with_metadata.tflite\"\n",
    "\n",
    "#download sample audio file \n",
    "audio_file_name = 'speech_16000_hz_mono.wav'\n",
    "url = f'https://storage.googleapis.com/mediapipe-assets/{audio_file_name}'\n",
    "url = urllib.request.urlretrieve(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c887b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseOptions = mp.tasks.BaseOptions(model)\n",
    "options = mp.tasks.audio.AudioClassifierOptions(base_options=baseOptions, max_results=4)\n",
    "classifier = mp.tasks.audio.AudioClassifier.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2543590",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, data = wavfile.read(audio_file_name)\n",
    "data = pre.normalize([data]).reshape(-1, 1)\n",
    "#data\n",
    "audio_format = containers.AudioData.create_from_array(data, rate)\n",
    "result = classifier.classify(audio_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228dc97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Speech'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].classifications[0].categories[0].category_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b01d0b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp 0: Speech, 0.5\n",
      "Timestamp 750: Speech, 0.95703125\n",
      "Timestamp 1500: Speech, 0.98828125\n",
      "Timestamp 3000: Speech, 0.984375\n",
      "Timestamp 4500: Silence, 0.33203125\n"
     ]
    }
   ],
   "source": [
    "for idx, timestamp in enumerate([0,750,1500,3000,4500]):\n",
    "    print(f'Timestamp {timestamp}: {result[idx].classifications[0].categories[0].category_name}, {result[idx].classifications[0].categories[0].score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
